{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58517613",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "import pickle\n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f721a282",
   "metadata": {},
   "outputs": [],
   "source": [
    "german_stop_words = stopwords.words('german')\n",
    "german_stop_words.append(\"fur\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b14e8a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "DATA_PATH = \"D:/10kgerdataset/\"\n",
    "TRAIN_CSV = \"train.csv\"\n",
    "TEST_CSV = \"test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59b623ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df_train = pd.read_csv(os.path.join(DATA_PATH, TRAIN_CSV))\n",
    "    df_test = pd.read_csv(os.path.join(DATA_PATH, TEST_CSV))\n",
    "except FileNotFoundError:\n",
    "    print(\"File was not found at specific location.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da7b7187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(document: str) -> str:\n",
    "    return re.sub(r'[^\\w\\s]', '', document)\n",
    "\n",
    "def remove_numbers(document: str) -> str:\n",
    "    return re.sub(r'$\\d+\\W+|\\b\\d+\\b|\\W+\\d+$', '', document)\n",
    "\n",
    "def map_umlaut(document: str) -> str:\n",
    "    umlaut_mapping = {\n",
    "        \"ß\": \"b\",\n",
    "        \"ü\": \"u\",\n",
    "        \"ä\": \"a\",\n",
    "        \"ö\": \"o\",\n",
    "        \"ë\": \"e\",\n",
    "    }\n",
    "    for k, v in umlaut_mapping.items():\n",
    "        document = document.replace(k, v)\n",
    "    return document\n",
    "\n",
    "def stop_word_removal(document: str) -> str:\n",
    "    return \" \".join(w for w in document.split() if w not in german_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21e59a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = load_vocab(\"vocabulary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3f39557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pre_processing_pipeline(df, tokenize: bool):\n",
    "    new_df = df.copy(deep=False)\n",
    "    \n",
    "    new_df[\"text\"] = new_df[\"text\"].str.lower()\n",
    "    new_df[\"label\"] = new_df[\"label\"].str.lower()\n",
    "    \n",
    "    new_df = new_df.dropna()\n",
    "    \n",
    "    new_df[\"text\"] = new_df[\"text\"].apply(remove_punctuation)\n",
    "    new_df[\"text\"] = new_df[\"text\"].apply(remove_numbers)\n",
    "    new_df[\"text\"] = new_df[\"text\"].apply(map_umlaut)\n",
    "    new_df[\"text\"] = new_df[\"text\"].apply(stop_word_removal)\n",
    "    \n",
    "    if tokenize:\n",
    "        new_df[\"text\"] = new_df[\"text\"].apply(lambda x: x.split())\n",
    "        new_df[\"text\"] = new_df[\"text\"].apply(lambda x: vocab(x))\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0692a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tokenizer(document: str) -> list:\n",
    "    return document.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35e08661",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = run_pre_processing_pipeline(df_train, True)\n",
    "df_test = run_pre_processing_pipeline(df_test, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "473098db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"text\"].apply(lambda x: len(x)).mean()\n",
    "max_length_batch = df_train[\"text\"][33:64].apply(lambda x: len(x)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e6e02346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "923"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e7161664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([31, 923])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f2ccfac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.stack([F.pad(torch.tensor(l, dtype=torch.int), (0, max_length_batch - len(l))) for l in df_train['text'][33:64]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "00bda3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = torch.nn.Embedding(len(vocab), 4, padding_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6a3d29b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1612,  0.2437,  0.4255,  0.6899],\n",
       "        [ 0.1357, -0.5789, -0.4601,  0.8077],\n",
       "        [-0.8990,  0.6507,  0.9905, -0.4202],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer(b)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e955be3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf3989cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d6c7c943",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.array(df_train[\"text\"])\n",
    "vocab = build_vocab_from_iterator(train_x, specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5e90b24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def save_vocab(vocab, path):\n",
    "    output = open(path, 'wb')\n",
    "    pickle.dump(vocab, output)\n",
    "    output.close()\n",
    "\n",
    "def load_vocab(path):\n",
    "    output = open(path, 'rb')\n",
    "    vocabulary = pickle.load(output)\n",
    "    output.close\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aab99bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_vocab(vocab, \"vocabulary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "787d674f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = load_vocab(\"vocabulary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a5c08303",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = torch.tensor(a(df_train[\"text\"][0]), dtype=torch.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3bf8371c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([221])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b6302d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8a2f0ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   352,  24088,    226,    204,  14200, 179203, 183228,   4274,      9,\n",
       "           806,     24,   4515,   4255,   2372, 167108,    261,      3,   1345,\n",
       "             3,  34016,   2073,  18606, 144188,      8,    554,  34340,   1206,\n",
       "          8968,   1940,    536,    765,     14,    299,     40,     67,    870,\n",
       "            51,     64,     17,   1474,      7,    638,  15374,      4,    450,\n",
       "           575,   2430,    337,   1247,     13,    805,   1505,   4019,  58645,\n",
       "             7,    509,      7,    553,   4255,   8968,     32,    189,   9917,\n",
       "           656,     19,   5499,   1345,   2073,     89,   7539,      7,   9582,\n",
       "         20899, 105111,   2804,    602, 110475,  28057,  28861, 165967,  91221,\n",
       "            14,    325,     28,   2073,   2372,  34360,     11,     21, 137325,\n",
       "           113,     28,   2073,   1077,  34340,    325,    294,      3,     34,\n",
       "          3070,   2178,    188,     47,  92872,   4692,    330,    325,     41,\n",
       "        180743,    348,    229,  54975,   8968,   1940,    536,  58162,   6976,\n",
       "            98,    484,   3070,   3843,   8526,    117,   1248,   6934,    455,\n",
       "           640,  26607,    352, 144192, 176437,   3347,   3338,    113,     32,\n",
       "         53149,   1304,   3679,   6976, 132084,   1366,    347,     44,    472,\n",
       "            32,  53149,   1304,    580,      7,      5,  42914,   2569,     76,\n",
       "          1390,    511,  13923,    330,      3,   8968,  22074,      4,   8041,\n",
       "           235,  24360,  53911,      4,   8277,    757,    511,  48744,   5682,\n",
       "         34340,   1093, 111228,    286,    294,      5,    375,      7,  55912,\n",
       "        100700,      5,    375,      7,    188,  71617,    230,      5,     28,\n",
       "          1020,    101,   2809,   1087,  34340,     28, 143588,     95,      5,\n",
       "            94,     23,    633,   8543, 143587, 121892,     34,  44716,    268,\n",
       "         15431,    527,   2445,  44259,  13595,    141,    289,    365,   1570,\n",
       "         44259,   1087,  34340,      3,   6852], dtype=torch.int32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f7f44aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([     0,    352,  24088,    226,    204,  14200, 179203, 183228,   4274,\n",
       "             9,    806,     24,   4515,   4255,   2372, 167108,    261,      3,\n",
       "          1345,      3,  34016,   2073,  18606, 144188,      8,    554,  34340,\n",
       "          1206,   8968,   1940,    536,    765,     14,    299,     40,     67,\n",
       "           870,     51,     64,     17,   1474,      7,    638,  15374,      4,\n",
       "           450,    575,   2430,    337,   1247,     13,    805,   1505,   4019,\n",
       "         58645,      7,    509,      7,    553,   4255,   8968,     32,    189,\n",
       "          9917,    656,     19,   5499,   1345,   2073,     89,   7539,      7,\n",
       "          9582,  20899, 105111,   2804,    602, 110475,  28057,  28861, 165967,\n",
       "         91221,     14,    325,     28,   2073,   2372,  34360,     11,     21,\n",
       "        137325,    113,     28,   2073,   1077,  34340,    325,    294,      3,\n",
       "            34,   3070,   2178,    188,     47,  92872,   4692,    330,    325,\n",
       "            41, 180743,    348,    229,  54975,   8968,   1940,    536,  58162,\n",
       "          6976,     98,    484,   3070,   3843,   8526,    117,   1248,   6934,\n",
       "           455,    640,  26607,    352, 144192, 176437,   3347,   3338,    113,\n",
       "            32,  53149,   1304,   3679,   6976, 132084,   1366,    347,     44,\n",
       "           472,     32,  53149,   1304,    580,      7,      5,  42914,   2569,\n",
       "            76,   1390,    511,  13923,    330,      3,   8968,  22074,      4,\n",
       "          8041,    235,  24360,  53911,      4,   8277,    757,    511,  48744,\n",
       "          5682,  34340,   1093, 111228,    286,    294,      5,    375,      7,\n",
       "         55912, 100700,      5,    375,      7,    188,  71617,    230,      5,\n",
       "            28,   1020,    101,   2809,   1087,  34340,     28, 143588,     95,\n",
       "             5,     94,     23,    633,   8543, 143587, 121892,     34,  44716,\n",
       "           268,  15431,    527,   2445,  44259,  13595,    141,    289,    365,\n",
       "          1570,  44259,   1087,  34340,      3,   6852,      0],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.pad(seq, (1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8776cc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GnadDataset(Dataset):\n",
    "    def __init__(self, x_train, y_train):\n",
    "        x = run_preprocessing_pipeline(df)\n",
    "        \n",
    "        self.x_train = torch.from_numpy(x_train)\n",
    "        self.y_train = torch.from_numpy(y_train)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.x_train.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.x_train[index], self.y_train[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea4ccfc4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12536/3766771926.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGnadDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"label\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12536/2760468307.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x_train, y_train)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mGnadDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "dataset = GnadDataset(np.array(df_train[\"text\"]), np.array(df_train[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bce3171b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(df_train[\"text\"]).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f913f8fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchtext'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12536/206956007.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchtext'"
     ]
    }
   ],
   "source": [
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee63391",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle-cell-segmentation",
   "language": "python",
   "name": "kaggle-cell-segmentation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
